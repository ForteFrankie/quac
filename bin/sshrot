#!/usr/bin/env python

'''
Run the given command on another host via ssh, "intelligently" selecting the
other host. The rules are:

1. If $SLURM_NODELIST exists, use the hosts listed there. Otherwise, use
   localhost.

2. Rotate jobs among those hosts.

The script uses a couple of unusual ssh arguments:

* BatchMode=yes, which means don't try to ask the user for authentication
  information, just fail instead. For example, SSH keys and a running SSH
  agent will work.

* ControlMaster=auto, which tries to multiplex multiple SSH connections over
  one TCP connection, conserving the latter resource.

  There is a race condition in setting up multiple simultaneous connections
  with ControlMaster=auto. Each will conclude that they are the master and try
  to create the control socket, but one will get there first and the others
  will fail with "ControlSocket [...] already exists, disabling multiplexing".
  This is a known bug, supposedly fixed a long time ago
  (https://bugzilla.mindrot.org/show_bug.cgi?id=1349), but it sure fails for
  me on Ubuntu 13.04.

  This warning doesn't actually prevent the connection, it just wastes a TCP
  connection and prints noise on stderr.

  The workaround is to pause approximately 1/20-1/10 second between the first
  and second invocations.

Warnings/notes/quirks:

* sshrot doesn't do anything to limit the number of jobs on any given host.

* This script drops state files in the current directory. Because they are
  needed for subsequent invocations, and sshrot doesn't know how many of these
  there will be, some of the files must be cleaned up manually when you are
  done.

* If the state file names a host that is not in the node list, then we
  silently start over from the beginning of the host list.

* SSH daemons are configured with a limit on the number of sessions that can
  be multiplexed over one TCP connection; it is MaxSessions and it defaults to
  10. This script doesn't do anything to try to avoid that. (We can't simply
  track the number of connections per host in the state file, because we don't
  know when they end.)

* The remote command will be run in the current working directory. This means
  that the CWD must exist on the remote host!'''

# Copyright (c) 2012-2013 Los Alamos National Security, LLC, and others.

# N.B. lockf() is pretty horrible, as is the BSD flock() alternative, but they
# are good enough for here. See the man pages for the two C functions.

import fcntl
import io
import os
import sys

import quacpath
import u

# scontrol show hostname $SLURM_NODELIST
nodes = ['localhost']
statef = io.open('sshrot.state', 'a+b')

# Need exclusive access to the state file, so lock before proceeding. This
# will block until we can have the lock.
fcntl.lockf(statef.fileno(), fcntl.LOCK_EX)

# read state
try:
   lastnode = u.pickle_load(statef)
   curnode = nodes[(nodes.index(lastnode) + 1) % len(nodes)]
except EOFError, ValueError:
   curnode = nodes[0]

# write state
u.pickle_dump(statef, curnode)

# we wrote the state we wanted, so release the lock
statef.close()

os.execvp('ssh', ['ssh',
                  '-o', 'BatchMode=yes',
                  '-o', 'ControlMaster=auto',
                  '-o', 'ControlPath=./sshsock.%n',
                  '-o', 'ControlPersist=1s',
                  curnode,
                  'cd', os.getcwd(), ';'] + sys.argv[1:])

