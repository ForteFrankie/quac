#!/usr/bin/env python

'''
Transform input files in a directory into a set of files containing pickled
n-gram time series with 1-day granularity. Input can be Twitter .all.tsv files
or Wikimedia pageview files; in the latter case, each article title becomes an
n-gram.'''

# Copyright (c) 2012-2013 Los Alamos National Security, LLC, and others.

import glob
import os
import os.path
import subprocess as sp

import numpy as np

import quacpath
import qr.base
import qr.scripting
import math_
import u
l = u.l


help_epilogue = '''
Note that FILE must be a *directory*: either containing preprocessed tweets or
the root of the Wikimedia pageview log tree. Output is in JOBDIR/out/.
''' + qr.scripting.help_epilogue


ap = qr.scripting.ArgumentParser(description=__doc__, epilog=help_epilogue)
gr = ap.add_argument_group('n-gram stuff')
gr.add_argument('-n',
                type=int,
                metavar='N',
                default=2,
                help='n-gram size (default 2) (ignored for Wikimedia)')
gr.add_argument('--min-occur',
                type=int,
                metavar='N',
                default=10,
                help='drop n-grams rarer than this (default 10 occurrences)')
gr.add_argument('--run',
                type=int,
                help='run make with -j N after job setup')
gr.add_argument('--clean',
                action='store_true',
                help='run "make clean" after job completion')

args = qr.scripting.parse_args(ap)
u.configure(None)
u.logging_init('ngbld')

if (len(args.inputs) != 1):
   ap.error('too many inputs')


### Main ###

def main():

   l.info('starting')

   if (os.path.exists('%s/tweet_ct.gp.pdf' % (args.inputs[0]))):
      l.info('input appears to be tweets')
      j = Tweet_Job()
   else:
      l.info('input appears to be Wikimedia pageview logs')
      j = Wikimedia_Job()

   l.info('loading metadata')
   j.metadata_load()
   l.info('setting up job')
   j.setup()
   l.info('writing totals')
   j.totals_write()

   if (args.run is not None):
      l.info('running job')
      qr.scripting.run(args, args.run)
      if (args.clean):
         l.info('cleaning up job')
         qr.scripting.clean(args)

   l.info('done')


### Classes ###

class Job(object):

   def metadata_load(self):
      self.metadata = u.pickle_load('%s/metadata' % (args.inputs[0]))

   def setup(self):
      self.args_munge()
      qr.scripting.setup(args)

   def totals_write(self):
      total = self.totals_build()
      u.pickle_dump('%s/out/total' % (args.jobdir), total)


class Tweet_Job(Job):

   def args_munge(self):
      args.python = 'qr.ngramtime.Tweet_Job' # kind of a hack?
      args.pyargs = qr.base.encode({ 'n': args.n,
                                     'min_occur': args.min_occur })
      args.inputs = glob.glob('%s/*.all.tsv' % (args.inputs[0]))

   def totals_build(self):
      cts = [v['count'] for (k, v) in sorted(self.metadata['days'].iteritems())]
      cts = math_.Date_Vector(min(self.metadata['days'].iterkeys()),
                              np.array(cts, dtype=np.float32))
      return { 'ngram':      None,
               'total':      sum(cts),
               'series':     cts }


### Bootstrap ###

if (__name__ == '__main__'):
   try:
      main()
   except sp.CalledProcessError, x:
      u.abort('subprocess failed with return code %d' % (x.returncode))


#  LocalWords:  gp ngram
