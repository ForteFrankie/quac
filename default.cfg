# ALL paths in this file are relative to the directory containing the
# configuration file specified on the command line (NOT the config file
# currently being read).
#
# Importantly, that means no paths can be set in default.cfg, because there
# might be no --config option.

# NOTE: Do not edit this file to put in your custom configuration; this is
# just the defaults. See README for more info on configuration.

[path]
### Various paths.

# Load this other config file (only for the config file specified on the
# command line).
next_config =

# This directory is appended to sys.path.
#
# FIXME: This is really the wrong way to do this. Just set $PYTHONPATH in the
# shell.
pythonpath_append =

# Location of the log file. (Note that more detailed logs are also printed to
# stdout, if it's a TTY.)
log =


[coll]
### Configuration for the collector.

# Directory in which to store collected tweet files.
tweets_dir =

# Username and password for Twitter login. (FIXME: This should be changed to
# oauth eventually, but tweetstream doesn't support that yet.)
tw_username =
tw_password =

# Location of the file containing keywords. If this is blank, a
# statuses/sample stream is started (i.e., random sample of all tweets);
# otherwise, a statuses/filter stream with the keywords in the file.
keywords_file =

# Maximum number of keywords to track. This just mirrors the Twitter limit
# (see https://dev.twitter.com/docs/streaming-api/methods) in order to provide
# more useful errors.
keywords_limit = 400

# How many tweets to store per file? (Currently, this is tuned to yield
# approximately 5 files per day with a 1% sample.)
tweets_per_file = 500000

# Log a heartbeat at the DEBUG level at this interval. Must be a power of two
# (in order to support our simple algorithm for heartbeating more frequently
# at startup.)
seconds_per_heartbeat = 256  ; must be a power of two


## Some network parameters.

# If true, do not use a proxy even if the environment suggests one.
no_proxy = false

# If non-empty, bind to this IP address when connecting to Twitter.
source_ip =

# Timeout in seconds on the HTTP socket.
socket_timeout = 10

# Reconnect backoff parameters.
#
# Initial delay (in seconds) after a stable connection fails.
reconnect_delay_base = 10.0
# Each time we reconnect again before reaching a stable connection, wait this
# many times longer than the last reconnect delay...
reconnect_delay_mult = 2.0
# ... until we are waiting this long (in seconds), which is the maximum.
reconnect_delay_max = 1800  ; 1/2 hour

# A connection which stays up this long (in seconds) is assumed to be stable,
# and we reset the backoff.
connect_ok_duration = 120

# This limits the number of connections before we assume something significant
# is wrong and abort. Specifically, if more than _limit connections happen
# within _interval seconds, abort. Note that the limit must be generous enough
# to actually reach given a slowly but repeatedly failing connection, i.e.,
# repeated _delay_max + _ok_duration must trigger the limit.
connect_limit = 23
connect_limit_interval = 43200  ; 12 hours


[pars]
### Configuration for the raw tweet parser

# The loader is tolerant of parsing failures, but if more than this many occur
# per file, abort.
parse_failure_max = 10

# Use this pytz time zone to split tweets into days. WARNING: Be sure to
# specify a time zone which does not observe daylight savings time, or you
# will get anomalies when daylight time is enabled and disabled.
#
# FIXME: I'm pretty much completely baffled as to how someone might get a time
# zone that does. "MST" seems to work -- no daylight time on April 18 --- but
# "MDT", "US/Mountain", and "America/Denver" all seem to also not observe
# daylight time. WTF?
local_timezone = UTC

# How much memory should `sort` use? (--buffer-size option)
# http://www.gnu.org/software/coreutils/manual/html_node/sort-invocation.html
sort_mem = 50%%


[tops]
### Configuration for the Topsy API

apikey =

# See Topsy API docs...
count_method = citation
