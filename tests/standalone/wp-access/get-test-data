#!/bin/bash

# Copyright (c) 2012-2013 Los Alamos National Security, LLC, and others.

# This script extracts a subset of the Wikimedia access logs. You probably
# don't need to run it, since the data are included with QUAC.
#
# It takes one argument: the root directory of the Wikimedia data you want to
# pull from.

extract () {
    file=$(basename $1)
    month=$(basename $(dirname $1))
    year=$(echo $month | sed -e 's/...$//')
    echo $year/$month/$file
    zcat $1 | egrep '^(en|ru) .*(Sandy|Halloween|%D0%A5%D1%8D%D0%BB%D0%BB%D0%BE%D1%83%D0%B8%D0%BD)' | gzip -9 > $year/$month/$file
}

mkdir -p 2012/2012-10
mkdir -p 2012/2012-11

for file in $1/2012/2012-10/pagecounts-201210{28,29,30,31}-*.gz; do
    extract $file
done

for file in $1/2012/2012-11/pagecounts-201211{01,02,03,04}-*.gz; do
    extract $file
done

cp $1/metadata .

# yes, we are writing Python as a here document in a bash script...
python <<EOF
import pickle_glue
fp = pickle_glue.File('metadata', writable=True)
for p in fp.data['projects'].keys():
   if (p not in ('en', 'ru')):
      del fp.data['projects'][p]
fp.commit()
EOF
